1/10/15

W786 - C. Titus Brown - How Well Can We Reconstruct Metagenome Content? Thoughts and Data on Metagenome Assembly

Reconstructing metagenomes from shotgun data.

Not talking about 16S. Shotgun is collecting samples, extracting DNA, sequence fragments,  and then you analyze it. "Sequence it all and let the bioinformaticians sort it out." That is, don't try to fiddle too much with the molecular biology - much can be sorted computationally.

To assemble or not? If the goal is to reconstruct phylogenetic content and predict functional potential of ensemble, you can either analyze short reads directly, OR you can assemble and THEN analyze (with weighted contains). So which to do?

Assembly is a bad bioinformatics technique - uses a lot of heuristics, bad software.

But - it can be useful. For stuff like this, you want to assemble. The length of the alignment means that you're passing a better single to blast for homology searches. Specificity is much better than just short reads.

Few assembly benchmarks have been done. 
We usually take unknown data and run it with new software & publish on it - which is a terrible way to do software.

Shakya et al 2013 - built a mock community so they KNEW what it was, then did real sequencing of the mock community. 101 bp PE reads, as well as other comparison sequencing.
What they found:
* Metagenome seq outperformed rRNA primer sets
* Illumina is good if you already know what you're looking for and you're just counting
* 454 with MG-RAST doesn't work very well at all with default parameters. So don't do that. Can change the perimeters.

What about assembly? His lab has been making a tutorial (since otherwise, there aren't really standards). Kalamazoo Metagenome Assembly protocol.

They used that to benchmark that mock community dataset. Tried three different assemblers (Velvet, IDBA, SPAdes). Also applied three different filterings. Since they have a known answer, they can compare with Quast.
Note - if something works on mock communities, it might not work on real ones (and probably won't).

IDBA and SPAdes outperform Velvet for genome fraction recovered (90-91%). Those two are pretty similar overall.

Computational cost - Quality takes a lot of RAM, which is why they do Diginorm and Partition.

Project is still in progress.
What is NOT being assembled, and why? Low coverage? Strain variation? Something else?
The mock community also gets 10 MB of sequence that isn't supposed to be there - probably contamination.
MEGAHIT is a good assembler.

90% recovery is pretty good - relatively few misassembles, too.

* You don't misassemble sequences (not systematically)
* You DO need big computers (for now)
* It's still technically tricky, but there's hope.

Everything they did here is reproducible and open. Search for "khmer protocols"

During questions, again stressed the importance of having better known standards, so we can actually trust our protocols.



W038 - Alexandre R. Caetano - De Novo Genome Assembly of the South American Freshwater Fish Tambaqui (Colossoma macropomum)

(Talk started before I arrived, so I don't have the beginning)

First round of assembly - one lane with shotgun and one lane with mate-pair
Partial assemblies using ~25% of each MP library size class and all 400+800 shotgun data available (if you throw out a lot of mate pair entires, the N50 drops)
That's only the case for the 10 kbp library - it's better than 15 kb, and much better than 5 kb.

Second round - additional reads. One lane with 400 bp SG, one with 800, and one lane with mate pair.
# of N's in the assembly was initially 33% of reads, but after gap filling, it dropped to 10%.

Quality check:
Detection of "universal" genes using CEGMA (run prior to gap filling)
85% of CEGMA core genes found complete
9% found partially
So pretty good.

Automated annotation: used MAKER2. Used the Mexican tetra to serve as the source of ESTs, since they don't have them for the actual species they're sequencing.

MAKER2 found 23,632 gene models found, ~20,000 shared with the tetra.

Variant calling - After filtering for Q20, have 3.6 million high-quality SNPs, and I think about 300,000 indels.

Future:
Data from other assemblers
RNA-seq to improve gene prediction
Detection of markers within and between related species

Used Nextera, so it doesn't go through PCR.



W788 - Mick Watson - The Microbial Proteome Associated with High Methane Emissions in Cattle Determined By Shotgun Metagenomic Sequencing

Food security - Everyone in the world having access to the food they need to survive. We don't do this well - despite all the obese people, there are a LOT of hungry people. Lots of challenges coming down the pipe, too - population increase, changes in consumer demand, globalization, climate change, competition for resources (like water), and Westerners who want to eat "happy chickens".

Three gorges damn - just to show that humans change the environment. It shifted so much mass that the day is now 0.06 microseconds longer.

Similarly, humans have changed our livestock, even over just ~45 years. That's all just through breeding. See van der Steen, Prall and Plastow, 2005 J. Anim Sci.
We need to keep this up, since we need these improvements to feed our species.

He studies gut rumen metagenomics. Why?
* Energy from food - microbiome could perhaps be used to get MORE energy from the food by manipulating microbiome.
* Novel enzyme discovery - Scientifically, it's a novel environment
* Methane emissions - entirely microbial in origin. And the cows burp it out, not from the other end.

No relationship between methane emissions and metaGENOMIC abundance of methanogenic archaea, but there is with metaTRANSCRIPTOMIC abundance. That was in a GR paper, anyway. Mick's data doesn't support this. (The Shi et al. paper looked at sheep, though, and Mick looked at cattle)

Matched steers based on breed and diet, looked at methane emissions. Also separated high and low methane emitters.
High methane emitters DO correlate with high archaeal abundance.

Enzyme abundance - matched for breed and diet, the abundance of several enzymes is associated with methane production.

What's in there? Assembled all 8 metagenomes from the cattle using MetaVelvet, predicted genes with Prokka, annotated using Pfam domains. 1.5 million gene/protein predictions, less than half have any known domain (and that includes domains of unknown function). Even in 8 samples, thousands of novel enzymes to look at.

Figuring out what all those enzymes DO is hard - as biologists, we don't really have a good system for tackling this (at scale?).

Metagenomic assembly - Working on a cattle metagenomics dataset, tried various assemblers

Mick: "There's regular velvet, and there's version specifically for metagenomics."
Titus: "But you're the only person who uses it now."
Mick: "...Yeah."

But you can't do the whole dataset - as Titus warned, you'll run out of RAM. 

So they did a smaller dataset. When you map back to the assembly with BWA, IDBA-UD works reasonably well.

Need to use complete genes in these studies, which is tricky in metagenomics, as orthologs often look like repeats, so a LOT of contigs start or end in the middle of a gene.
IDBA-UD did well relative to the others, BUT it still mostly found fragmented genes

Metagenomic assembly is an unsolved problem, need lots of RAM, and assemblies fail in the middle of genes.
IDBA-UC looks to be the best assembler so far.



W789 - Timothy P.L. Smith - Characterization of the Bovine Nasopharyngeal Microbiome in the Context of Respiratory Disease and Treatment

Dealing with Bovine Respiratory Disease Complex (BRDC) - 25-30% morbidity after feed lot.

Multi-factorial, stress-related disease. Mortality associated with bacterial pleurpneumonia.

Control measures - vaccination against the disease, vaccination against specific pathogens. Limited protective ability, though, and antibiotics not always effective.

First experiment - stress the cattle so they'll get sick (since they need to study sick cattle). Mixing and highway transport are big sterssors, make them "high risk" cattle.

Some were metaphylactically injected, and the rest weren't. Three sets of these treatments, from cattle from separate sources.

Studies nasophyryngial swabs, rectal samples, blood phenotypes (cytokines and immune repertoires)

Profiling the microbial community with 16S. The problem, though, is that most of the DNA you get is cow, not microbial. Bustamante's selection technique gets rid of too much DNA, and it costs them too much to just sequence everything, so they're punting on that and just doing 16S.

Can now also do full-length sequencing of 16S with PacBio.

Analysis: WebMGA vs Greengenes give somewhat different answers. Lots of mycoplasma, though.

Substantial animal-to-animal variation, even within the same sale barn.

All animals that received metaphylactic macrolide treatment had increased mycoplasma (N=7)

Summary:
* Full-length 16S does achieve species-level discrimination
* Nasopharynx is relatively low-diversity compared to, say, rumen.
* (And there were more, but the slide changed)



###################################



Plant Genome Engineering

(Note: this session had a small, low screen in a crowded room, so I was only able to see about the top half of each slide.)



W597 - Dan Voytas & Bob ??? - Strategies for the Targeted Modification of Plant Genomes

Research dedicated to developing SITE-DIRECTED DNA sequence modification metrologies and applications. Modifications often stimulated by DSBs.

Desired outcomes: mutagenesis, gene replacement or edition, targeted gene insertion (like from the transgene world, creating molecular stacks), targeted structural changes.

Example: targeting soybean Dcl1a and 1b with ZFNs (dicer family). Used one ZFN with two paralogous targets, and recovered two T0 plants with multiple mutations. Able to "stack" double mutants.

CRISPRs deleted a 76.7 kb region in Medicago. That's 4 CRISPRs, not just one.

Dan Voytas -

He's going to talk about using a "homologous template" to serve in repair, so you're able to put in your desired modification.

Using Agrobacterium to achieve gene targeting: the bacterial T-DNA goes from the bacterium to the plant nucleus, and has the machinery to make the cut. It ALSO contains, on the same construct, the modified template you'll use for HR repair.

Harnessing plant DNA viruses (geminiviruses) to get efficient targeting. Similar to before, but now the tDNA has the viral replication machinery. That lets it circularize in the plant nuclease, AND replicate so you have more copies to work with.

Replicons enhance gene targeting frequencies 10 to 100-fold. Partially due to increase in donor molecules, AND by pushing the host cell into S-phase, making HR more likely.

Introduced a promoter to drive Ant1. Since this is plants, you can take the part that was modified (explants) and grow it back into a whole plant. 

Questions: larger donor plasmids have less efficient rolling-circle replication, so keep that in mind.

Have they changed GC content of the replicons (lowering it) do geminivirus has an easier time b/c it'll be less methylated? They haven't done that yet.



W598 - Caixia Gao - Developing Genome Editing Technologies for Crop Improvement

Working in rice and wheat. 

SSNs enable efficient genome engineering. Their research focuses on ZFN and CRISPR/Cas9.

4-5 months from TALEN or CRISPR design to produce knock-out mutants.

Showed example of a ~1.3 kb deletion from TALEN

CRISPR: Rice uses OsU3 promoter, wheat uses TaU6 promoter

Homology-directed repair (HDR) in rice: Just inserting some restriction sites, but it works.

Creation of fragrant rice by genome editing. Done by making deletions in Badh2. TALEN-induced mutations in OsBADH2 gene, which were transmitted to T1 and T2 generations. Making these deletions increase 2AP content, the fragrant compound.

Interestingly, new indel mutations were detected in subsequent generations. Looks like 1 bp deletions were expanding in T1 and T2.

They also used CRISPR for OsBADH2, and found similar results.

Powdery mildew - a very destructive disease in wheat. They combated this by targeting three TaML homoeoalleles with TALENs. Knockout of all siz alleles of TaMLO in wheat confers resistance to powdery mildew. (She later noted that this does run into regulatory challenges in the US)

NHEJ-mediated GFP insertion into wheat protoplasts.



W599 - Puchta Holger - The CRISPR/Cas System can be used as Nuclease for in planta Gene Targeting and as Paired Nickases for Directed Mutagenesis in Arabidopsis Resulting in Heritable Progeny

Nuclease-induced genome engineering

Background: years ago we were using I-SceI to introduce DSBs - at least to show what happens when you make that break. You could put T-DNA in the break, and it needn't be homologous for it to integrate (why sometimes you get the CRISPR transgenes integrating therein). Lower frequency than homologous, of course.

In planta gene targeting technique - gene targeting that takes place during the life cycle of the plant. Idea is to do the targeting in all cells, and then going to the seeds to get what you want. The donor is integrated into the donor via transformation. The way they do this still involves I-SceI in his example - your donor has the same homology arms as whatever flanks your I-SceI site of interest, and that's how you get HR.

The idea now is to do the same sort of thing with targeted nucleases (like the CRISPR system). Turns out it works efficiently. Verified with Southern blots.

Used the agrobacterium approach on ADH1, TT4, etc. They work.

Germline transmission in their hands is 15-20%.

Off-target effects: To deal with this, they converted CRISPR/Cas into a nickase. Did that by knocking out one of the nuclease motifs, so it only cuts on one side. Make two nicks and you get the DSB you needed, but with twice the specificity.
(I am surprised that this solution also works in plants, with with multiple genome duplications, etc.)

Mentioned at the end - we now have the tools to make a synthetic plant genome.



W600 - Feng Zhang - Highly Efficient Genome Editing in Crops

From Celectis. Idea is to create better food products through genome editing.

Efficient delivery methods are key to success. There are a couple way to do it: agrobacterium, particle bombardment, PEG or electroporation, and RNA or DNA viruses.

Protoplast transformation: what people did before agrobacterium.

Targeted gene editing in N. benthamiana. They do TALEN transformation, regeneration, and mutant screening. No need to select the plants on selective media because the transformation efficiency is very high.

Multiplex gene knockout in one generation: Trying to knock out four genes at once; 17% of screened plants did.
Results in a significant reduction of N-glycosilation in mutant plants.

Potato: trying protoplast transformation in commercial varieties. 
Cold-induced sweetening reduces potato storage quality, so they're trying to tackle that.
TALENs to knock out the gene responsible for the sweetening. 
Transgene-free mutant plants were identified, and did have reduced reducing sugar (not a typo) and acrylamide levels.
This substantially reduced the darkening of the color after CIS.



W601 - Sandeep Kumar - A Modular Gene Targeting System for Sequential Transgene Stacking in Plants

SmartStax has 8 transgenes stacked into one product. Crops with multiple traits. Typically, the transgenes reside on different chromosomes, so it's tricky to put them together and KEEP them together. 

The solution is the molecular stack since transgenes can be stacked into a single locus.

They're heavily invested in ZFN, so that's what they're using.

They use a modular and sequential gene targeting and stacking strategy. Involves switching back and forth between selectable markers every other generation. Can keep using the same ZFN to do this.

Particle bombardment used to insert donor and ZFN. Done on a T1 homo target (T0 is selfed to get homo). Looks like about 30% mutational efficiency overall.

Targeting confirmed via Southern.


